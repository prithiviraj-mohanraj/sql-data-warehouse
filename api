Script to Generate Safe DESCRIBE Output
scripts/03_extract_columns_raw.sh
#!/bin/bash

SCOPE="../output/scope_summary.csv"
SQL_FILE="../logs/describe_tables.sql"
RAW_OUT="../logs/describe_raw.txt"

mkdir -p ../logs

> $SQL_FILE

# Generate SQL with markers
tail -n +2 $SCOPE | while IFS=',' read SCHEMA TABLE
do
    echo "SELECT 'START:${SCHEMA}.${TABLE}';" >> $SQL_FILE
    echo "DESCRIBE ${SCHEMA}.${TABLE};" >> $SQL_FILE
    echo "SELECT 'END:${SCHEMA}.${TABLE}';" >> $SQL_FILE
done

# Run once (single connection)
impala-shell -k -i your-host -f $SQL_FILE -B > $RAW_OUT

echo "Raw describe output with table markers → $RAW_OUT"


Option 1 — Parse Using Python (Recommended)
scripts/parse_columns.py
import csv

input_file = "../logs/describe_raw.txt"
output_file = "../output/table_columns.csv"

with open(input_file) as f, open(output_file, "w", newline="") as out:
    writer = csv.writer(out)
    writer.writerow(["schema", "table", "column", "data_type"])

    current_schema = None
    current_table = None

    for line in f:
        line = line.strip()

        if line.startswith("START:"):
            schema_table = line.split(":")[1]
            current_schema, current_table = schema_table.split(".")
            continue

        if line.startswith("END:"):
            current_schema = None
            current_table = None
            continue

        if current_schema and line and not line.startswith("#"):
            parts = line.split()
            if len(parts) >= 2:
                writer.writerow([current_schema, current_table, parts[0], parts[1]])

print("Parsed column file created.")


Option 2 — Parse Using AWK (If Python Not Allowed)

awk '
/START:/ {
    split($0,a,":");
    split(a[2],b,".");
    schema=b[1]; table=b[2];
    next;
}
/END:/ { schema=""; table=""; next; }
NF>=2 && schema!="" && $1!="#" {
    print schema","table","$1","$2;
}
' ../logs/describe_raw.txt > ../output/table_columns.csv

import csv

input_file = "../logs/describe_raw.txt"
output_file = "../output/table_columns.csv"

with open(input_file) as f, open(output_file, "w", newline="") as out:
    writer = csv.writer(out)
    writer.writerow(["schema", "table", "column", "data_type", "column_type"])

    current_schema = None
    current_table = None
    column_type = "BASE"

    for line in f:
        line = line.strip()

        if line.startswith("START:"):
            schema_table = line.split(":")[1]
            current_schema, current_table = schema_table.split(".")
            column_type = "BASE"
            continue

        if line.startswith("END:"):
            current_schema = None
            current_table = None
            continue

        # Detect partition section
        if "Partition Information" in line:
            column_type = "PARTITION"
            continue

        # Skip header lines
        if line.startswith("#") or line.startswith("col_name"):
            continue

        if current_schema and line:
            parts = line.split()
            if len(parts) >= 2:
                writer.writerow([
                    current_schema,
                    current_table,
                    parts[0],
                    parts[1],
                    column_type
                ])

print("Partition-safe column file created.")

Column Count Script (Python)

import csv
from collections import defaultdict

counts = defaultdict(lambda: {"BASE":0, "PARTITION":0})

with open("../output/table_columns.csv") as f:
    reader = csv.DictReader(f)
    for row in reader:
        key = (row["schema"], row["table"])
        counts[key][row["column_type"]] += 1

with open("../output/column_counts.csv", "w", newline="") as out:
    writer = csv.writer(out)
    writer.writerow(["schema","table","base_columns","partition_columns","total_columns"])

    for (schema, table), vals in counts.items():
        total = vals["BASE"] + vals["PARTITION"]
        writer.writerow([schema, table, vals["BASE"], vals["PARTITION"], total])

print("Column counts created.")
