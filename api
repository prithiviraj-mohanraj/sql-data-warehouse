validation/
â”œâ”€â”€ input/
â”‚   â”œâ”€â”€ migration_scope.csv
â”‚   â””â”€â”€ business_days.txt
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_all.sh
â”‚   â”œâ”€â”€ 01_check_schema.sh
â”‚   â”œâ”€â”€ 02_check_tables.sh
â”‚   â”œâ”€â”€ 03_extract_columns.sh
â”‚   â”œâ”€â”€ 04_column_validation.sh
â”‚   â”œâ”€â”€ 05_column_counts.sh
â”‚   â”œâ”€â”€ 06_metrics.sh
â”‚   â”œâ”€â”€ 07_extract_ddl.sh
â”‚   â””â”€â”€ 08_finalize.sh
â”œâ”€â”€ output/
â”œâ”€â”€ logs/
â””â”€â”€ README.md

input/migration_scope.csv
schema_name,table_name,column_name
sales,orders,order_id
sales,orders,amount
sales,customers,customer_id

input/business_days.txt
2024-01-01
2024-02-01
2024-03-01
scripts/run_all.sh
#!/bin/bash
set -e

echo "Starting Hive validation..."

cd "$(dirname "$0")"

mkdir -p ../output ../logs

bash 01_check_schema.sh
bash 02_check_tables.sh
bash 03_extract_columns.sh
bash 04_column_validation.sh
bash 05_column_counts.sh
bash 06_metrics.sh
bash 07_extract_ddl.sh
bash 08_finalize.sh

echo "Validation completed. Final file: output/final_validation.csv"


scripts/01_check_schema.sh

#!/bin/bash
INPUT="../input/migration_scope.csv"
OUT="../output/schemas.csv"

echo "schema,exists" > $OUT

cut -d',' -f1 $INPUT | tail -n +2 | sort -u | while read SCHEMA
do
    EXISTS=$(impala-shell -q "SHOW DATABASES LIKE '$SCHEMA';" -B | grep -w $SCHEMA || true)

    if [ -z "$EXISTS" ]; then
        echo "$SCHEMA,NO" >> $OUT
    else
        echo "$SCHEMA,YES" >> $OUT
    fi
done



scripts/02_check_tables.sh
#!/bin/bash
INPUT="../input/migration_scope.csv"
OUT="../output/tables.csv"

echo "schema,table,exists" > $OUT

tail -n +2 $INPUT | cut -d',' -f1,2 | sort -u | while IFS=',' read SCHEMA TABLE
do
    EXISTS=$(impala-shell -q "SHOW TABLES IN $SCHEMA LIKE '$TABLE';" -B | grep -w $TABLE || true)

    if [ -z "$EXISTS" ]; then
        echo "$SCHEMA,$TABLE,NO" >> $OUT
    else
        echo "$SCHEMA,$TABLE,YES" >> $OUT
    fi
done


scripts/03_extract_columns.sh

#!/bin/bash
INPUT="../input/migration_scope.csv"
OUT="../output/hive_columns.csv"

echo "schema,table,column,data_type" > $OUT

tail -n +2 $INPUT | cut -d',' -f1,2 | sort -u | while IFS=',' read SCHEMA TABLE
do
    impala-shell -q "DESCRIBE $SCHEMA.$TABLE;" -B | \
    awk -v s="$SCHEMA" -v t="$TABLE" 'NF>=2 {print s","t","$1","$2}' >> $OUT
done


#!/bin/bash
INPUT="../input/migration_scope.csv"
HIVE_COLS="../output/hive_columns.csv"
OUT="../output/column_validation.csv"

echo "schema,table,column,exists_in_hive" > $OUT

tail -n +2 $INPUT | while IFS=',' read SCHEMA TABLE COLUMN
do
    EXISTS=$(grep -i "^$SCHEMA,$TABLE,$COLUMN," $HIVE_COLS || true)

    if [ -z "$EXISTS" ]; then
        echo "$SCHEMA,$TABLE,$COLUMN,NO" >> $OUT
    else
        echo "$SCHEMA,$TABLE,$COLUMN,YES" >> $OUT
    fi
done


Column Counts per Table
ðŸ”¹ scripts/05_column_counts.sh


#!/bin/bash
HIVE_COLS="../output/hive_columns.csv"
OUT="../output/column_counts.csv"

echo "schema,table,column_count" > $OUT

tail -n +2 $HIVE_COLS | cut -d',' -f1,2 | sort | uniq -c | \
awk '{print $2","$3","$1}' >> $OUT

Metrics: Oldest Record & Counts
ðŸ”¹ scripts/06_metrics.sh

#!/bin/bash
INPUT="../input/migration_scope.csv"
DATES_FILE="../input/business_days.txt"
OUT="../output/metrics.csv"

HEADER="schema,table,oldest_business_day"
for DATE in $(cat $DATES_FILE); do
    HEADER="$HEADER,count_${DATE//-/_}"
done
echo $HEADER > $OUT

tail -n +2 $INPUT | cut -d',' -f1,2 | sort -u | while IFS=',' read SCHEMA TABLE
do
    echo "Processing metrics for $SCHEMA.$TABLE"

    OLDEST=$(impala-shell -q "SELECT MIN(business_day) FROM $SCHEMA.$TABLE;" -B | tail -n 1)

    ROW="$SCHEMA,$TABLE,$OLDEST"

    for DATE in $(cat $DATES_FILE)
    do
        CNT=$(impala-shell -q "SELECT COUNT(*) FROM $SCHEMA.$TABLE WHERE business_day='$DATE';" -B | tail -n 1)
        ROW="$ROW,$CNT"
    done

    echo $ROW >> $OUT
done


Extract Table DDL (Audit)
ðŸ”¹ scripts/07_extract_ddl.sh

#!/bin/bash
INPUT="../input/migration_scope.csv"
OUT="../output/table_ddl.sql"

> $OUT

tail -n +2 $INPUT | cut -d',' -f1,2 | sort -u | while IFS=',' read SCHEMA TABLE
do
    echo "-- $SCHEMA.$TABLE" >> $OUT
    impala-shell -q "SHOW CREATE TABLE $SCHEMA.$TABLE;" -B >> $OUT
    echo "" >> $OUT
done

Final Consolidation
ðŸ”¹ scripts/08_finalize.sh

#!/bin/bash

OUT="../output/final_validation.csv"

echo "schema,table,column,data_type,column_exists,column_count" > $OUT

join -t',' \
 <(sort ../output/hive_columns.csv) \
 <(sort ../output/column_validation.csv) \
 >> $OUT || true


Hive Validation Framework

Run:
cd scripts
bash run_all.sh

Outputs:
output/final_validation.csv â†’ main comparison file
output/metrics.csv â†’ record counts & oldest dates
output/hive_columns.csv â†’ column inventory
output/table_ddl.sql â†’ audit DDL

